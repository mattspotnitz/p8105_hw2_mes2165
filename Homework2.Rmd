---
title: "Homework2"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

##Problem 1
Import and view
I will import the Mr. Trash Wheel sheet, clean its column names, and examine the structure, head, and tail of the data set.

Then, I will view the data set.
```{r, echo = TRUE}
df_one = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "Mr. Trash Wheel")
df_one = janitor::clean_names(df_one)
str(df_one)
head(df_one)
tail(df_one)
view(df_one)
```

#Clean dataset

I will  omit the last columns 'x15', 'x16', and 'x17', which do not contain data. Then I will drop other 'NA' values.
```{r}
df_two = select(df_one, -c("x15", "x16", "x17"))
view(df_two)
df_three = drop_na(df_two)
view(df_three)
```

#Calculate the number of sports balls
```{r}
sb = select(df_three, "sports_balls")
sum(sb)
```
4065 is the closest integer value of sports balls

This calculation could also be achieved by the "pull" function, which I will show below
```{r}
df_three %>% pull("sports_balls") %>% sum()

```
#Import and view

I will import the 2019 precipitation sheet, clean its column names, and examine the structure, head, and tail of the data set.

Then, I will view the data set.

```{r, echo = TRUE}
df_four = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2019 Precipitation")
df_four = janitor::clean_names(df_four)
str(df_four)
head(df_four)
tail(df_four)
view(df_four)
```
The first row contains column names.
I will clean the column names.
```{r, echo = TRUE}
df_five = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2019 Precipitation", skip = 1, col_names = TRUE)
df_five = janitor::clean_names(df_five)
str(df_five)
head(df_five)
tail(df_five)
view(df_five)
```

Now I will omit rows with missing data
```{r}
df_six = drop_na(df_five)
view(df_six)
```

I will add a year column to this data set
```{r}
df_2019 = df_six %>% mutate(year = 2019)
view(df_2019)
```

Now I will move on to the 2018 precipitation sheet
```{r, echo = TRUE}
df_seven = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2018 Precipitation")
df_seven = janitor::clean_names(df_seven)
str(df_seven)
head(df_seven)
tail(df_seven)
view(df_seven)
```

The first row contains column names.
I will clean the column names and drop the NA values
```{r, echo = TRUE}
df_eight = read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2018 Precipitation", skip = 1, col_names = TRUE)
df_eight = janitor::clean_names(df_eight)
str(df_eight)
head(df_eight)
tail(df_eight)
view(df_eight)
df_nine = drop_na(df_eight)
view(df_nine)
```

I will add a year column to this data set.
```{r}
df_2018 = df_nine %>% mutate(year = 2018)
view(df_2018)
```
I will convert from numeric value to month name for 2018.
```{r}
df_2018_m = df_2018 %>% mutate(month_name = month.name[month])
view(df_2018_m)
```

I will convert from numeric value to month name for 2019.
```{r}
df_2019_m = df_2019 %>% mutate(month_name = month.name[month])
view(df_2019_m)
```

I will merge precipitation datasets.
```{r}
precipitation = merge(df_2018_m, df_2019_m, by = c("year", "month", "month_name", "total"), all=TRUE)
view(precipitation)
```

I will remove then numeric month column from the dataset.
Then, I will rename the month_name column as month to merge with  the Mr. Trash Wheel dataset better.

```{r}
precipitation_m = precipitation %>% select("year", "month_name", "total") %>% rename("month" = "month_name", "total_precipitation" = "total")
view(precipitation_m)
```
I will characterize the precipitation data sets by viewing the structure, head and tail.

```{r}
str(precipitation)
head(precipitation)
tail(precipitation)
```
This data set has 18 observations and 4 variables.  There are 4 columns.  Of those, 3 columns are in numerical format and month_name is in a character format.

I will merge Mr. Trash Wheel with precipitation data.
```{r}
data_set_full = merge(df_three, precipitation_m, by = c("year", "month"), all=TRUE)
view(data_set_full)
```

I will characterize the merged data sets by viewing the structure, head and tail.

```{r}
str(data_set_full)
head(data_set_full)
tail(data_set_full)
```
The data set has 344 observations and is 344 x 15 in size.  There are 15 columns. Of those, 13 are in nmerical format. 1 column is a character format and the date column is in time stamp format.

I will drop missing values from the dataset, which will remove all values before 2018.
```{r}
data_set_edit = drop_na(data_set_full)
view(data_set_edit)
```

I will characterize the new data set by viewing the structure, head and tail.

```{r}
str(data_set_edit)
head(data_set_edit)
tail(data_set_edit)
```
The data set has 123 observations and is 344 x 15 in size.  There are 15 columns. Of those, 13 are in nmerical format. 1 column is a character format and the date column is in time stamp format.

I will view the data set.
```{r}
view(data_set_edit)
```
I will calculate the median precipitation in 2018.
```{r}
 data_set_edit %>% filter (year == 2018) %>% pull (total_precipitation) %>% median()
```
The median precipitation in 2018 was 6.11.

I will calculate the median sports balls in 2019.
```{r}
 data_set_edit %>% filter (year == 2019) %>% pull (sports_balls) %>% median()
```
The median number of sports balls was 8.5 in 2019.

I will calculate the median weight in tons, volume in cubic volume, number of plastic bottles, amount of polystyrene, and homes powered in 2018.
```{r}
 data_set_edit %>% filter (year == 2018) %>% pull (weight_tons) %>% median() ##weight
data_set_edit %>% filter (year == 2018) %>% pull (volume_cubic_yards) %>% median() #cubic volume
data_set_edit %>% filter (year == 2018) %>% pull (plastic_bottles) %>% median() #plastic bottles
data_set_edit %>% filter (year == 2018) %>% pull (polystyrene) %>% median() #ploystyrene
data_set_edit %>% filter (year == 2018) %>% pull (homes_powered) %>% median() #homes powered
```
The median weight is 3 tons, median volume is 15 cubic yards, number of plastic botles is 1200, amount of polystyrene is 1020, and number of homes powered is 55.

I will calculate the median weight in tons, volume in cubic volume, number of plastic bottles, amount of polystyrene, and homes powered in 2019
```{r}
 data_set_edit %>% filter (year == 2019) %>% pull (weight_tons) %>% median() ##weight
data_set_edit %>% filter (year == 2019) %>% pull (volume_cubic_yards) %>% median() #cubic volume
data_set_edit %>% filter (year == 2019) %>% pull (plastic_bottles) %>% median() #plastic bottles
data_set_edit %>% filter (year == 2019) %>% pull (polystyrene) %>% median() #ploystyrene
data_set_edit %>% filter (year == 2019) %>% pull (homes_powered) %>% median() #homes powered
```
The median weight is 3 tons, median volume is 15 cubic yards, number of plastic botles is 1075, amount of polystyrene is 1350, and number of homes powered is 51.

#Problem 2
First,I will clean the data in pols-months and characterize the data frame.
```{r}
df_pols = read_csv("pols-month.csv")
df_pols = janitor::clean_names(df_pols)
str(df_pols)
head(df_pols)
tail(df_pols)
view(df_pols)
```

Now I will drop any missing values and reassess the data frame.
```{r}
df_pols %>% drop_na()
str(df_pols)
head(df_pols)
tail(df_pols)
```
There were no missing values.
Now I will separate the month value.
```{r}
df_pols_two = separate(df_pols, mon, c("year", "month", "day"), "-")
head(df_pols_two)
```

Now I will replace the month number with the month name. 
First, I will convert the month into a numeric type.
```{r}
month_numeric = df_pols_two %>% pull(month) %>% as.numeric()
df_pols_three = df_pols_two %>% mutate(month = month_numeric)
str(df_pols_three)
```
Now I will convert the numeric values to month names.
```{r}
df_pols_four = df_pols_three %>% mutate(month = month.name[month])
str(df_pols_four)
```
Now, I will convert the year and day into a numeric types.
```{r}
year_numeric = df_pols_four %>% pull(year) %>% as.numeric()
df_pols_four = df_pols_four %>% mutate(year = year_numeric)
day_numeric = df_pols_four %>% pull(day) %>% as.numeric()
df_pols_four = df_pols_four %>% mutate(day = day_numeric)

str(df_pols_four)
```


Now I will create a president variable.
```{r}
df_pols_five = pivot_longer(
  df_pols_four, c(prez_dem, prez_gop), names_to = "president", values_to = c("prez_values")
)
str(df_pols_five)
```

Now I will replace the president value names.
```{r}
president_edit = df_pols_five %>% pull(president) %>% str_replace_all("prez_dem", "dem") %>% str_replace_all("prez_gop", "gop")
```

Now I will replace the old president vector with the edited president vector.
```{r}
df_pols_five = df_pols_five %>% mutate (president = president_edit)
str (df_pols_five)
```
Now I will omit the day and president values columns.
```{r}
df_pols_six = select(df_pols_five, -c("day", "prez_values"))
str(df_pols_six)
```
I will import and characterize snip.csv.
```{r}

df_snip_one = read_csv("snp.csv")
df_snip_one = janitor::clean_names(df_snip_one)
str(df_snip_one)
head(df_snip_one)
tail(df_snip_one)
view(df_snip_one)
```

Now I will drop any missing values and reassess the data frame.
```{r}
df_snip_one %>% drop_na()
str(df_snip_one)
head(df_snip_one)
tail(df_snip_one)
```
There were no missing values.

I will convert the 2 digit year date into a 4 digit year date.
```{r}
date_vector = df_snip_one %>% pull(date) %>% lubridate::mdy()
df_snip_two = mutate(df_snip_one, date = date_vector)
df_snip_two
```
Some of the dates are impossible, as they have occurred after the year 2050. I will separate the values and then fix the year column.
Now I will separate the month value.
```{r}
df_snip_two = separate(df_snip_two, date, c("year", "month", "day"), "-")
head(df_snip_two)
```
Now, I will convert the year and day into a numeric types.
```{r}
year_numeric = df_snip_two %>% pull(year) %>% as.numeric()
df_snip_two = df_snip_two %>% mutate(year = year_numeric)
month_numeric = df_snip_two %>% pull(month) %>% as.numeric()
df_snip_two = df_snip_two %>% mutate(month = month_numeric)

day_numeric = df_snip_two %>% pull(day) %>% as.numeric()
df_snip_two = df_snip_two %>% mutate(day = day_numeric)

str(df_snip_two)
```
I will rearrange so that year and month are the leading columns.
```{r}
close = df_snip_two %>% pull(close)
df_snip_two = select(df_snip_two, -"close")
df_snip_two = mutate(df_snip_two, close)
df_snip_two = df_snip_two %>% arrange (year)
view (df_snip_two)
```
Now, I will convert the year column into plausible values.
If the year >2020, a value of 100 should be subtracted from it.
```{r}
df_snip_three = df_snip_two %>% mutate (year = ifelse(test = (year > 2020), yes = year - 100, no = year)) %>% arrange(year)

  
view(df_snip_three)
```
I will convert the month from numbers to names.
```{r}
df_snip_three = df_snip_three %>% mutate(month = month.name[month])
str(df_snip_three)
```
I will remove the day column to be consistent with pols.
```{r}
df_snip_three = select(df_snip_three, -c("day"))
str(df_snip_three)
```
I will import and characterize unemployment.csv.
```{r}

df_un_one = read_csv("unemployment.csv")
df_un_one = janitor::clean_names(df_un_one)
str(df_un_one)
head(df_un_one)
tail(df_un_one)
view(df_un_one)
```

I will do a long pivot on the month names.
```{r}
df_un_two = pivot_longer(
  df_un_one, c(jan:dec), names_to = "month", values_to = c("counts")
)
str(df_un_two)
view(df_un_two)
```

I will replace the month names in the unemployment data set to standardize them with other data sets.
```{r}
un_month_edit = df_un_two %>% pull(month) %>% str_replace_all("jan", "January") %>% str_replace_all("feb", "February") %>% str_replace_all("mar", "March") %>% str_replace_all("apr", "April")%>% str_replace_all("may", "May") %>% str_replace_all("jun", "June") %>% str_replace_all("jul", "July") %>% str_replace_all("aug", "August") %>% str_replace_all("sep", "September") %>% str_replace_all("oct", "October") %>% str_replace_all("nov", "November") %>% str_replace_all("dec", "December")

un_month_edit
```

Now, I will replace the old month vector with the new month vector.
```{r}
df_un_three = df_un_two %>% mutate (month = un_month_edit)
str (df_un_three)
```
Now I will merge snp and pols.
```{r}
str(df_snip_three)
str(df_pols_six)
merge_one = merge(df_snip_three, df_pols_six, by = c("year", "month"), all=TRUE)
str(merge_one)
```

Now I will merge the output with unemployment.
```{r}
str(df_un_three)
merge_two = merge(merge_one, df_un_three, by = c("year", "month"), all=TRUE)
str(merge_two)
```

I will drop missing values.
```{r}
merge_three = drop_na(merge_two)
str(merge_three)
view(merge_three)
```
###Description of output
I want to review each data set. First, let's review the pols data set
```{r}
str (df_pols_six)
```
This data set has 1,644 observations and 9 variables.  Of the 9 variables, 7 are numeric.  The month and president columns are characters. Month indicates the name of the month year and I created a president variables that takes political party as inputs.  Additionally, the year is captured, as wll as the number of governors, senators, and house representatives who belonged to each poltical party. The range of years is 1947 through 2015.

Now I will look at the snp data set.
```{r}
str (df_snip_three)
```
This data set has 787 observations and 3 variables.  The month name is a character variable. The year and closing values of the S&P index are numerical values. The range of years is 1950 through 2015.

I will look at the merged dataset of pols and snp.
```{r}
str (merge_one)
```
This data set has 1645 observations and 10 variables.  The merge was done on year and month.  The year and month data are shown, as well as the political affiliations of presidents, governors, senators, and representatives. The range of years in 1947 through 2015. The S&P index as also shown in the merge.  There are multiple 'NA' values.

I will look at the unemployment data set.
```{r}
str (df_un_three)
```

This data set has 816 observations and 3 variables.  The month name is caracter variables and the year and percentage of unemployed people are continuous variables. The range of years is 1948 through 2015.

I will look at the merge of the unemployment data set with the other data sets.
```{r}
str (merge_two)
```
This data set has 1650 observations and 11 variables.  The month name and presidents' political affiliations are character variables. The others are numerical variables.  In addition to year, numerical variables include the number of governors, senators and represenatives in each major poltiical party. The range of years is 1947 through 2015. There are multiple 'NA' values.

I will look at how many rows are lost after dropping the 'NA' values.
```{r}
merge_three = drop_na(merge_two)
str(merge_three)
view(merge_three)
```
This data set has 1572 observations and 11 variables. There were 78 rows with 'NA' observations. The range of years is now 1950 through 2015.

#Problem 3
First I will import and characterize the baby names data set
```{r}
df_names = read_csv("Popular_Baby_Names.csv")
df_names = janitor::clean_names(df_names)
str(df_names)
head(df_names)
tail(df_names)
view(df_names)
```
Names, strings, and duplicates have to be addressed.

First I will convert the names into all capital letters and removed unwanted punctuation.
Then I will replace the old names in the dataframe with the new names.
```{r}
capital_names = df_names %>% pull(childs_first_name) %>% toupper() %>% str_replace_all("[[:punct:]]", " ")
df_names_two = df_names %>% mutate(childs_first_name = capital_names)
str(df_names_two)
```
Now I will remove duplicated rows.
```{r}
df_names_three = unique(df_names_two)
str(df_names_three)
```
I will filter the data frame to entries that contain olivia, and then make a pivot table that is wider.
```{r}
olivia = df_names_three %>% filter(childs_first_name == "OLIVIA")  %>% arrange(year_of_birth) %>% select(-c(gender, count))
olivia
olivia %>% pivot_wider(names_from = year_of_birth, values_from = rank)
```

I will filter the data frame to entries for male children, and then make a pivot table.
```{r}
boys = df_names_three %>% filter(gender == "MALE")  %>% arrange(year_of_birth) %>% select(-c(count))
boys
boys %>% pivot_wider(names_from = year_of_birth, values_from = rank)
```
I will now make a scatter plot of white non-hispanic male children born in 2016 that shows the number of children with an ame on the y-axis and rank in popularity on the x-axis. First I will filter the dataframe, and then I will plot the data.

```{r}
library(ggplot2)
df_plot = df_names_three %>% filter(ethnicity == "WHITE NON HISPANIC") %>% filter(gender=="MALE") %>% filter(year_of_birth ==2016)
ggplot(df_plot, aes(rank, count)) + geom_point() +
  labs(
    title = "White Non-Hispanic Male Children Born in 2016",
    x = "Rank in Popularity",
    y = "Number of Children"
  ) + theme_minimal()
```
Here, I have combined the multiple filter condiitions into one command. The result is the same.
```{r}
library(ggplot2)
df_plot = df_names_three %>% filter(ethnicity == "WHITE NON HISPANIC" & gender=="MALE" & year_of_birth ==2016)
ggplot(df_plot, aes(rank, count)) + geom_point() +
  labs(
    title = "White Non-Hispanic Male Children Born in 2016",
    x = "Rank in Popularity",
    y = "Number of Children"
  ) + theme_minimal()
png('mes2165_plot.png')
```
